# 5.7. Diving Deeper: LLM Architecture | LLM Architecture and RAG 🏛️🔍

In the forthcoming video, we provide a detailed explanation of the essential components that constitute a Large Language Model's architecture. This video aims to extend your comprehension of the LLM architecture, contributing to your foundational understanding of the field.

📺 **[Watch the Video](https://youtu.be/OXZQBXBvOR4?t=704)**

**What we learned:**
- The User Interface Component is designed to pose questions
- The Storage Layer, which utilizes Vector DB or Vector Indexes
- The Service, Chain, or Pipeline Layer, which is instrumental in the model's functioning (with a brief mention of the Chain Library used for chaining prompts)

**Summary So Far:**
Throughout this module, we've transitioned from an introduction of Retrieval Augmented Generation (RAG) to an in-depth look at Large Language Model architecture. This sets the foundation for grasping the more complex aspects of LLMs.

Before we proceed, let’s quickly summarize our learnings on LLM Architecture.

# 5.8. Summary: LLM Architecture | LLM Architecture and RAG 📚🔍

In the final video of this module, Anup Surendran wraps up by summarizing key concepts and distinctions in the realm of Large Language Models. Covered topics include:

- Fine-tuning vs. In-context learning
- Limitations of context
- Personalized data storage in Vector DB/Index formats
- Major architectural components for your data

📺 **[Watch the Video](https://youtu.be/OXZQBXBvOR4?t=963)**

This comprehensive summary will help solidify the various concepts and technical components discussed throughout the module. Happy Learning! 🚀🧠

[Next Lesson](../Level-5/LLM-Architecture-and-RAG-Part-5.md)📖👣🔜

[Previous Lesson](../Level-5/LLM-Architecture-and-RAG-Part-3.md)🔙📚
